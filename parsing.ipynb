{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickOsipov/otus-ds-basic-tutorial/blob/main/parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4d860f",
      "metadata": {
        "id": "0b4d860f"
      },
      "source": [
        "# Парсинг данных в Python\n",
        "\n",
        "Краткий интерактивный ноутбук для быстрого освоения **искусства извлечения данных** — на русском языке. Каждый раздел содержит пример кода и краткое пояснение[1]."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0422eb",
      "metadata": {
        "id": "9e0422eb"
      },
      "source": [
        "## Что такое парсинг и зачем он нужен?\n",
        "\n",
        "**Парсинг — это суперсила для Data Scientist**: Умение извлекать нужную информацию из любого источника — сайтов, файлов, API.\n",
        "\n",
        "**Почему парсинг критически важен**:\n",
        "- **80% времени** тратится на сбор и очистку данных\n",
        "- **Автоматизация**: Вместо копирования вручную — один скрипт на миллионы записей\n",
        "- **Актуальность**: Получение свежих данных в реальном времени\n",
        "- **Масштаб**: Обработка данных, недоступных для ручного анализа\n",
        "\n",
        "## Импорт необходимых библиотек\n",
        "\n",
        "**Арсенал парсера**: Каждая библиотека — специализированный инструмент для своих задач:\n",
        "- **requests** — ваш проводник в мир веб-страниц  \n",
        "- **BeautifulSoup** — библиотека для разбора HTML/XML документов\n",
        "- **pandas** — мастер табличных данных\n",
        "- **json** — переводчик JavaScript объектов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57a0b28",
      "metadata": {
        "id": "a57a0b28"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "from urllib.parse import urljoin\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33bb4379",
      "metadata": {
        "id": "33bb4379"
      },
      "source": [
        "## Урок первый: Парсинг HTML с BeautifulSoup\n",
        "\n",
        "**Знакомьтесь с BeautifulSoup** — библиотека для работы с веб-страницами!\n",
        "\n",
        "**Практическое применение**:\n",
        "- Извлечение цен с сайтов интернет-магазинов\n",
        "- Сбор новостей и статей\n",
        "- Анализ структуры веб-страниц\n",
        "- Автоматизация заполнения отчетов из веб-источников"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a025226",
      "metadata": {
        "id": "6a025226"
      },
      "outputs": [],
      "source": [
        "# Пример HTML для парсинга\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "<head><title>Пример страницы</title></head>\n",
        "<body>\n",
        "    <h1>Заголовок страницы</h1>\n",
        "    <div class=\"content\">\n",
        "        <p>Первый параграф</p>\n",
        "        <p>Второй параграф</p>\n",
        "        <ul>\n",
        "            <li>Элемент списка 1</li>\n",
        "            <li>Элемент списка 2</li>\n",
        "            <li>Элемент списка 3</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    <a href=\"https://example.com\">Ссылка</a>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Создание объекта BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "print(\"Заголовок страницы:\", soup.title.text)\n",
        "print(\"\\nЗаголовок h1:\", soup.h1.text)\n",
        "print(\"\\nВсе параграфы:\")\n",
        "for p in soup.find_all('p'):\n",
        "    print(\"-\", p.text)\n",
        "\n",
        "print(\"\\nЭлементы списка:\")\n",
        "for li in soup.find_all('li'):\n",
        "    print(\"-\", li.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9832cf2e",
      "metadata": {
        "id": "9832cf2e"
      },
      "source": [
        "## Урок второй: Парсинг JSON — язык современного веба\n",
        "\n",
        "**JSON — это эсперанто интернета**: Универсальный язык обмена данными между системами.\n",
        "\n",
        "**Аналогия для понимания**: Если HTML — это красиво оформленная книга, то JSON — это структурированная картотека в библиотеке. Все данные разложены по полочкам и легко находятся.\n",
        "\n",
        "**Где встречается JSON**:\n",
        "- **API ответы** — 99% современных API возвращают данные в JSON\n",
        "- **Конфигурационные файлы** — настройки приложений\n",
        "- **NoSQL базы данных** — MongoDB, CouchDB хранят данные в JSON-подобном формате\n",
        "- **AJAX запросы** — обмен данными между браузером и сервером"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ef548b",
      "metadata": {
        "id": "b7ef548b"
      },
      "outputs": [],
      "source": [
        "# Пример JSON данных\n",
        "json_data = '''\n",
        "{\n",
        "    \"name\": \"Иван Иванов\",\n",
        "    \"age\": 30,\n",
        "    \"city\": \"Москва\",\n",
        "    \"skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n",
        "    \"education\": {\n",
        "        \"degree\": \"Магистр\",\n",
        "        \"university\": \"МГУ\",\n",
        "        \"year\": 2020\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# Парсинг JSON\n",
        "data = json.loads(json_data)\n",
        "\n",
        "print(\"Имя:\", data['name'])\n",
        "print(\"Возраст:\", data['age'])\n",
        "print(\"Город:\", data['city'])\n",
        "print(\"Навыки:\", \", \".join(data['skills']))\n",
        "print(\"Образование:\", data['education']['degree'], \"в\", data['education']['university'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e15fbc",
      "metadata": {
        "id": "91e15fbc"
      },
      "source": [
        "## Урок третий: Парсинг CSV — основа табличных данных\n",
        "\n",
        "**CSV — это Excel без красивостей**: Чистые данные, максимальная совместимость.\n",
        "\n",
        "**Почему CSV так популярен**:\n",
        "- **Универсальность**: Открывается в любой программе — от блокнота до Excel\n",
        "- **Скорость**: Быстрее загружается и обрабатывается, чем Excel файлы  \n",
        "- **Размер**: Минимальный объем файлов\n",
        "- **Стандарт**: Используется везде — банки, биржи, научные исследования\n",
        "\n",
        "**Практическое применение**:\n",
        "- Экспорт отчетов из баз данных\n",
        "- Обмен данными между системами\n",
        "- Загрузка данных в машинное обучение\n",
        "- Анализ финансовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ec05763",
      "metadata": {
        "id": "5ec05763"
      },
      "outputs": [],
      "source": [
        "# Создание примера CSV данных\n",
        "csv_content = \"\"\"name,age,city,salary\n",
        "Иван Иванов,30,Москва,100000\n",
        "Петр Петров,25,Санкт-Петербург,80000\n",
        "Мария Сидорова,28,Екатеринбург,90000\n",
        "Анна Козлова,32,Новосибирск,95000\"\"\"\n",
        "\n",
        "# Сохранение в файл\n",
        "with open('example.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write(csv_content)\n",
        "\n",
        "# Парсинг с помощью pandas\n",
        "df = pd.read_csv('example.csv')\n",
        "print(\"Данные из CSV файла:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nСтатистика по зарплатам:\")\n",
        "print(f\"Средняя зарплата: {df['salary'].mean():,.0f}\")\n",
        "print(f\"Максимальная зарплата: {df['salary'].max():,.0f}\")\n",
        "print(f\"Минимальная зарплата: {df['salary'].min():,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc24664",
      "metadata": {
        "id": "0cc24664"
      },
      "source": [
        "## Урок четвертый: Парсинг XML — структурированные документы\n",
        "\n",
        "**XML — это HTML с правилами**: Более строгий, но гибкий формат для сложных иерархических данных.\n",
        "\n",
        "**Где используется XML**:\n",
        "- **Корпоративные системы** — обмен данными между большими системами\n",
        "- **Конфигурационные файлы** — настройки сложных приложений\n",
        "- **SOAP веб-сервисы** — старый, но все еще используемый стандарт\n",
        "- **Банковские системы** — стандарты типа ISO 20022\n",
        "\n",
        "**Когда выбирать XML вместо JSON**:\n",
        "- Нужны атрибуты у элементов\n",
        "- Требуется валидация структуры (XSD схемы)\n",
        "- Работа с пространствами имен\n",
        "- Сложная иерархия данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd58f8d",
      "metadata": {
        "id": "8bd58f8d"
      },
      "outputs": [],
      "source": [
        "# Пример XML данных\n",
        "xml_content = \"\"\"\n",
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<books>\n",
        "    <book id=\"1\">\n",
        "        <title>Война и мир</title>\n",
        "        <author>Лев Толстой</author>\n",
        "        <year>1869</year>\n",
        "        <genre>Роман</genre>\n",
        "    </book>\n",
        "    <book id=\"2\">\n",
        "        <title>Преступление и наказание</title>\n",
        "        <author>Федор Достоевский</author>\n",
        "        <year>1866</year>\n",
        "        <genre>Роман</genre>\n",
        "    </book>\n",
        "    <book id=\"3\">\n",
        "        <title>Мастер и Маргарита</title>\n",
        "        <author>Михаил Булгаков</author>\n",
        "        <year>1967</year>\n",
        "        <genre>Фантастика</genre>\n",
        "    </book>\n",
        "</books>\n",
        "\"\"\"\n",
        "\n",
        "# Парсинг XML\n",
        "root = ET.fromstring(xml_content)\n",
        "\n",
        "print(\"Книги в библиотеке:\")\n",
        "for book in root.findall('book'):\n",
        "    book_id = book.get('id')\n",
        "    title = book.find('title').text\n",
        "    author = book.find('author').text\n",
        "    year = book.find('year').text\n",
        "    genre = book.find('genre').text\n",
        "\n",
        "    print(f\"ID: {book_id}\")\n",
        "    print(f\"  Название: {title}\")\n",
        "    print(f\"  Автор: {author}\")\n",
        "    print(f\"  Год: {year}\")\n",
        "    print(f\"  Жанр: {genre}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abac48b",
      "metadata": {
        "id": "4abac48b"
      },
      "source": [
        "## Урок пятый: Веб-скрапинг — этично и эффективно\n",
        "\n",
        "**Веб-скрапинг — это автоматизированная разведка**: Программы собирают данные вместо вас, но с соблюдением правил приличия.\n",
        "\n",
        "**ВАЖНЫЕ ПРИНЦИПЫ ЭТИЧНОГО СКРАПИНГА**:\n",
        "- **robots.txt** — всегда проверяйте, что разрешено\n",
        "- **Задержки** — не перегружайте сервер запросами\n",
        "- **User-Agent** — представьтесь корректно\n",
        "- **Terms of Service** — соблюдайте правила сайта\n",
        "\n",
        "**Практические применения**:\n",
        "- Мониторинг цен конкурентов  \n",
        "- Сбор новостей и аналитики\n",
        "- Исследование рынков\n",
        "- Автоматизация рутинных задач"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde68659",
      "metadata": {
        "id": "dde68659"
      },
      "outputs": [],
      "source": [
        "# Функция для безопасного получения веб-страницы\n",
        "def safe_request(url, delay=1):\n",
        "    \"\"\"\n",
        "    Безопасный запрос к веб-странице с задержкой\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        time.sleep(delay)  # Вежливая задержка\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        return response\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе: {e}\")\n",
        "        return None\n",
        "\n",
        "# Пример использования (замените на реальный URL для тестирования)\n",
        "# url = \"https://httpbin.org/html\"\n",
        "# response = safe_request(url)\n",
        "#\n",
        "# if response:\n",
        "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
        "#     title = soup.find('title')\n",
        "#     if title:\n",
        "#         print(f\"Заголовок страницы: {title.text}\")\n",
        "\n",
        "print(\"Функция safe_request готова к использованию\")\n",
        "print(\"Не забывайте соблюдать robots.txt и условия использования сайтов!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cecdd2",
      "metadata": {
        "id": "d0cecdd2"
      },
      "source": [
        "## Урок шестой: Обработка ошибок — защита от неожиданностей\n",
        "\n",
        "**Золотое правило парсинга**: \"Всегда ожидайте неожиданное!\" Данные из реального мира грязные, неполные и непредсказуемые.\n",
        "\n",
        "**Аналогия**: Парсинг без обработки ошибок — это вождение автомобиля без ремней безопасности. Можно проехать без проблем, но первая же неожиданность станет катастрофой.\n",
        "\n",
        "**Типичные проблемы в реальных данных**:\n",
        "- **Отсутствующие элементы** — ожидаемого поля нет на странице\n",
        "- **Невалидный JSON** — лишняя запятая ломает весь парсинг\n",
        "- **Изменилась структура** — сайт обновился, ваш код сломался\n",
        "- **Проблемы с кодировкой** — русские символы превратились в ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cd1d98",
      "metadata": {
        "id": "90cd1d98"
      },
      "outputs": [],
      "source": [
        "def safe_parse_json(json_string):\n",
        "    \"\"\"\n",
        "    Безопасный парсинг JSON с обработкой ошибок\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return json.loads(json_string)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Ошибка парсинга JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def safe_extract_text(soup, selector, default=\"Не найдено\"):\n",
        "    \"\"\"\n",
        "    Безопасное извлечение текста из HTML\n",
        "    \"\"\"\n",
        "    try:\n",
        "        element = soup.select_one(selector)\n",
        "        return element.text.strip() if element else default\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка извлечения текста: {e}\")\n",
        "        return default\n",
        "\n",
        "# Примеры использования\n",
        "valid_json = '{\"name\": \"Тест\", \"value\": 123}'\n",
        "invalid_json = '{\"name\": \"Тест\", \"value\":}'\n",
        "\n",
        "print(\"Парсинг корректного JSON:\")\n",
        "result1 = safe_parse_json(valid_json)\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nПарсинг некорректного JSON:\")\n",
        "result2 = safe_parse_json(invalid_json)\n",
        "print(result2)\n",
        "\n",
        "# Пример безопасного извлечения из HTML\n",
        "html = \"<div class='content'><h1>Заголовок</h1></div>\"\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "print(\"\\nИзвлечение существующего элемента:\")\n",
        "title = safe_extract_text(soup, 'h1')\n",
        "print(f\"Заголовок: {title}\")\n",
        "\n",
        "print(\"\\nИзвлечение несуществующего элемента:\")\n",
        "subtitle = safe_extract_text(soup, 'h2')\n",
        "print(f\"Подзаголовок: {subtitle}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0390db",
      "metadata": {
        "id": "3b0390db"
      },
      "source": [
        "## Урок седьмой: Практическое задание — ваша первая победа\n",
        "\n",
        "**Время показать мастерство!** Лучший способ изучить парсинг — попрактиковаться на реальной задаче.\n",
        "\n",
        "**Совет наставника**: Начните с простого, постепенно усложняйте. Каждая маленькая победа приближает вас к мастерству парсинга.\n",
        "\n",
        "**Идеи для развития навыков**:\n",
        "- Парсинг курсов валют с сайта ЦБ РФ\n",
        "- Извлечение заголовков новостей с новостных сайтов  \n",
        "- Анализ вакансий с job-сайтов\n",
        "- Мониторинг цен в интернет-магазинах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd08f57f",
      "metadata": {
        "id": "cd08f57f"
      },
      "outputs": [],
      "source": [
        "# Место для вашего кода\n",
        "# Задание: создайте функцию для парсинга данных о погоде из JSON\n",
        "# или HTML таблицы с данными\n",
        "\n",
        "def parse_weather_data(data):\n",
        "    \"\"\"\n",
        "    Функция для парсинга данных о погоде\n",
        "    data может быть JSON строкой или HTML\n",
        "    \"\"\"\n",
        "    # Ваш код здесь\n",
        "    pass\n",
        "\n",
        "# Пример данных для тестирования\n",
        "weather_json = '''\n",
        "{\n",
        "    \"city\": \"Москва\",\n",
        "    \"temperature\": -5,\n",
        "    \"humidity\": 65,\n",
        "    \"condition\": \"Снег\",\n",
        "    \"wind_speed\": 12\n",
        "}\n",
        "'''\n",
        "\n",
        "print(\"Добавьте свой код для парсинга данных о погоде!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8beb230b",
      "metadata": {
        "id": "8beb230b"
      },
      "source": [
        "---\n",
        "\n",
        "## Заключение\n",
        "\n",
        "**Что вы изучили**: Основы парсинга данных — ключевой навык для любого аналитика. Теперь вы знаете:\n",
        "- Как работать с HTML, JSON, CSV и XML форматами\n",
        "- Секреты этичного веб-скрапинга\n",
        "- Важность обработки ошибок в реальных проектах\n",
        "- Практические инструменты для повседневной работы\n",
        "\n",
        "**Важные принципы, которые нужно помнить**:\n",
        "- **Этика прежде всего** — соблюдайте правила сайтов\n",
        "- **Обрабатывайте ошибки** — реальные данные всегда грязные\n",
        "- **Уважайте серверы** — используйте задержки между запросами\n",
        "- **Изучайте robots.txt** — это карта разрешений для скрапинга\n",
        "\n",
        "**Продвинутые техники для изучения**:\n",
        "- **Selenium** — для парсинга JavaScript-сайтов\n",
        "- **Scrapy** — промышленный фреймворк для больших проектов\n",
        "- **API-интеграции** — часто лучше, чем скрапинг\n",
        "- **Обходы защиты** — captcha, rate limits, IP-блокировки\n",
        "\n",
        "**Полезные библиотеки для роста**:\n",
        "- `requests-html` — JavaScript рендеринг\n",
        "- `lxml` — быстрый XML/HTML парсер  \n",
        "- `scrapy` — профессиональный веб-скрапинг\n",
        "- `selenium` — автоматизация браузера\n",
        "- `aiohttp` — асинхронные запросы\n",
        "\n",
        "> **Дополнительные материалы и документация доступны в [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html) и [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)[1].**\n",
        "\n",
        "[1] https://realpython.com/python-web-scraping-practical-introduction/"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}